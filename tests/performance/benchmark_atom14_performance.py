#!/usr/bin/env python3
"""
Atom14 æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬

æµ‹è¯• ProtRepr ä¸­ Atom14 è½¬æ¢çš„æ€§èƒ½ï¼Œæ¯”è¾ƒä¼˜åŒ–å‰åçš„é€Ÿåº¦å·®å¼‚ã€‚
"""

import sys
from pathlib import Path
import time
import statistics
from typing import List, Tuple, Dict, Any

# å°†é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ src ç›®å½•æ·»åŠ åˆ° Python è§£é‡Šå™¨çš„æœç´¢è·¯å¾„ä¸­
sys.path.insert(0, str(Path(__file__).resolve().parent.parent / "src"))

import torch
import logging
import numpy as np

from protrepr.representations.atom14_converter import (
    protein_tensor_to_atom14, 
    CHAIN_GAP
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.WARNING, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)


class BenchmarkProteinTensor:
    """ç”¨äºåŸºå‡†æµ‹è¯•çš„ ProteinTensor æ¨¡æ‹Ÿç±»"""
    
    def __init__(self, coordinates, atom_types, residue_types, chain_ids, residue_numbers):
        self.coordinates = coordinates
        self.atom_types = atom_types
        self.residue_types = residue_types
        self.chain_ids = chain_ids
        self.residue_numbers = residue_numbers
        self.n_atoms = len(coordinates)
        self.n_residues = len(set((c.item(), r.item()) for c, r in zip(chain_ids, residue_numbers)))
    
    def to_torch(self):
        """è¿”å› torch æ ¼å¼çš„æ•°æ®"""
        return {
            "coordinates": self.coordinates,
            "atom_types": self.atom_types,
            "residue_types": self.residue_types,
            "chain_ids": self.chain_ids,
            "residue_numbers": self.residue_numbers
        }


def create_benchmark_data(num_chains: int, residues_per_chain: int, atoms_per_residue: int = 4) -> BenchmarkProteinTensor:
    """
    åˆ›å»ºåŸºå‡†æµ‹è¯•æ•°æ®ã€‚
    
    Args:
        num_chains: é“¾çš„æ•°é‡
        residues_per_chain: æ¯æ¡é“¾çš„æ®‹åŸºæ•°é‡
        atoms_per_residue: æ¯ä¸ªæ®‹åŸºçš„åŸå­æ•°é‡
        
    Returns:
        BenchmarkProteinTensor: æµ‹è¯•ç”¨çš„è›‹ç™½è´¨æ•°æ®
    """
    device = torch.device("cpu")
    
    total_residues = num_chains * residues_per_chain
    total_atoms = total_residues * atoms_per_residue
    
    # ç”Ÿæˆåæ ‡ï¼ˆéšæœºä½ç½®ï¼‰
    coordinates = torch.randn(total_atoms, 3, device=device) * 10.0
    
    # åŸå­ç±»å‹ (0=N, 1=CA, 2=C, 3=O)
    atom_types = torch.tensor([0, 1, 2, 3] * total_residues, device=device, dtype=torch.long)
    
    # æ®‹åŸºç±»å‹ï¼ˆéšæœºé€‰æ‹©æ ‡å‡†æ°¨åŸºé…¸ 0-19ï¼‰
    residue_types_per_residue = torch.randint(0, 20, (total_residues,), device=device)
    residue_types = torch.repeat_interleave(residue_types_per_residue, atoms_per_residue)
    
    # é“¾ID
    chain_ids = []
    for chain_id in range(num_chains):
        chain_atoms = residues_per_chain * atoms_per_residue
        chain_ids.append(torch.full((chain_atoms,), chain_id, device=device, dtype=torch.long))
    chain_ids = torch.cat(chain_ids)
    
    # æ®‹åŸºç¼–å·
    residue_numbers = []
    for chain_id in range(num_chains):
        for res_id in range(residues_per_chain):
            residue_numbers.extend([res_id + 1] * atoms_per_residue)
    residue_numbers = torch.tensor(residue_numbers, device=device, dtype=torch.long)
    
    return BenchmarkProteinTensor(
        coordinates=coordinates,
        atom_types=atom_types,
        residue_types=residue_types,
        chain_ids=chain_ids,
        residue_numbers=residue_numbers
    )


def time_function(func, *args, **kwargs) -> Tuple[Any, float]:
    """
    æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´ã€‚
    
    Args:
        func: è¦æµ‹è¯•çš„å‡½æ•°
        *args: å‡½æ•°å‚æ•°
        **kwargs: å‡½æ•°å…³é”®å­—å‚æ•°
        
    Returns:
        Tuple[Any, float]: (å‡½æ•°è¿”å›å€¼, æ‰§è¡Œæ—¶é—´ç§’)
    """
    start_time = time.perf_counter()
    result = func(*args, **kwargs)
    end_time = time.perf_counter()
    execution_time = end_time - start_time
    return result, execution_time


def benchmark_conversion(protein_tensor: BenchmarkProteinTensor, num_runs: int = 10) -> Dict[str, float]:
    """
    åŸºå‡†æµ‹è¯• ProteinTensor åˆ° Atom14 çš„è½¬æ¢æ€§èƒ½ã€‚
    
    Args:
        protein_tensor: æµ‹è¯•ç”¨çš„è›‹ç™½è´¨æ•°æ®
        num_runs: è¿è¡Œæ¬¡æ•°
        
    Returns:
        Dict[str, float]: æ€§èƒ½ç»Ÿè®¡æ•°æ®
    """
    times = []
    
    # é¢„çƒ­è¿è¡Œ
    for _ in range(2):
        _, _ = time_function(protein_tensor_to_atom14, protein_tensor, device=torch.device("cpu"))
    
    # æ­£å¼åŸºå‡†æµ‹è¯•
    for run in range(num_runs):
        result, exec_time = time_function(protein_tensor_to_atom14, protein_tensor, device=torch.device("cpu"))
        times.append(exec_time)
        
        # éªŒè¯ç»“æœæœ‰æ•ˆæ€§
        coords, atom_mask, res_mask, chain_ids, residue_types, residue_indices, chain_residue_indices, residue_names, atom_names = result
        assert coords.shape[0] > 0, "è½¬æ¢ç»“æœæ— æ•ˆ"
    
    return {
        'mean_time': statistics.mean(times),
        'median_time': statistics.median(times),
        'std_time': statistics.stdev(times) if len(times) > 1 else 0.0,
        'min_time': min(times),
        'max_time': max(times),
        'total_time': sum(times),
        'runs': num_runs
    }


def run_benchmark_suite():
    """è¿è¡Œå®Œæ•´çš„åŸºå‡†æµ‹è¯•å¥—ä»¶"""
    print("ğŸš€ å¼€å§‹ Atom14 æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•åœºæ™¯
    test_scenarios = [
        {"name": "å°å‹è›‹ç™½è´¨", "chains": 1, "residues_per_chain": 50, "atoms_per_residue": 4},
        {"name": "ä¸­å‹è›‹ç™½è´¨", "chains": 2, "residues_per_chain": 150, "atoms_per_residue": 4},
        {"name": "å¤§å‹è›‹ç™½è´¨", "chains": 4, "residues_per_chain": 300, "atoms_per_residue": 4},
        {"name": "å¤æ‚å¤šé“¾", "chains": 8, "residues_per_chain": 100, "atoms_per_residue": 4},
        {"name": "è¶…å¤§è›‹ç™½è´¨", "chains": 2, "residues_per_chain": 1000, "atoms_per_residue": 4},
    ]
    
    results = {}
    
    for scenario in test_scenarios:
        print(f"\nğŸ“Š æµ‹è¯•åœºæ™¯: {scenario['name']}")
        print(f"   - é“¾æ•°: {scenario['chains']}")
        print(f"   - æ¯é“¾æ®‹åŸºæ•°: {scenario['residues_per_chain']}")
        print(f"   - æ¯æ®‹åŸºåŸå­æ•°: {scenario['atoms_per_residue']}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        protein_data = create_benchmark_data(
            num_chains=scenario['chains'],
            residues_per_chain=scenario['residues_per_chain'],
            atoms_per_residue=scenario['atoms_per_residue']
        )
        
        total_atoms = protein_data.n_atoms
        total_residues = protein_data.n_residues
        
        print(f"   - æ€»åŸå­æ•°: {total_atoms:,}")
        print(f"   - æ€»æ®‹åŸºæ•°: {total_residues:,}")
        
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        print("   - è¿è¡ŒåŸºå‡†æµ‹è¯•...")
        
        benchmark_stats = benchmark_conversion(protein_data, num_runs=10)
        results[scenario['name']] = {
            **scenario,
            'total_atoms': total_atoms,
            'total_residues': total_residues,
            **benchmark_stats
        }
        
        # è¾“å‡ºç»“æœ
        print(f"   âœ… å¹³å‡æ—¶é—´: {benchmark_stats['mean_time']:.4f}s")
        print(f"   ğŸ“Š ä¸­ä½æ—¶é—´: {benchmark_stats['median_time']:.4f}s")
        print(f"   ğŸ“ˆ æ ‡å‡†å·®: {benchmark_stats['std_time']:.4f}s")
        print(f"   âš¡ æœ€å¿«æ—¶é—´: {benchmark_stats['min_time']:.4f}s")
        print(f"   ğŸŒ æœ€æ…¢æ—¶é—´: {benchmark_stats['max_time']:.4f}s")
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        atoms_per_second = total_atoms / benchmark_stats['mean_time']
        residues_per_second = total_residues / benchmark_stats['mean_time']
        
        print(f"   ğŸ”¥ å¤„ç†é€Ÿåº¦: {atoms_per_second:,.0f} åŸå­/ç§’")
        print(f"   ğŸ”¥ å¤„ç†é€Ÿåº¦: {residues_per_second:,.0f} æ®‹åŸº/ç§’")
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ€§èƒ½åŸºå‡†æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    print(f"{'åœºæ™¯åç§°':<12} {'åŸå­æ•°':<10} {'æ®‹åŸºæ•°':<8} {'å¹³å‡æ—¶é—´':<10} {'åŸå­/ç§’':<12} {'æ®‹åŸº/ç§’':<10}")
    print("-" * 70)
    
    for name, stats in results.items():
        atoms_per_sec = stats['total_atoms'] / stats['mean_time']
        residues_per_sec = stats['total_residues'] / stats['mean_time']
        
        print(f"{name:<12} {stats['total_atoms']:<10,} {stats['total_residues']:<8,} "
              f"{stats['mean_time']:<10.4f} {atoms_per_sec:<12,.0f} {residues_per_sec:<10,.0f}")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    import json
    output_file = Path(__file__).parent.parent / "benchmark_results_original.json"
    with open(output_file, 'w') as f:
        # è½¬æ¢numpyç±»å‹ä»¥ä¾¿JSONåºåˆ—åŒ–
        json_results = {}
        for name, stats in results.items():
            json_results[name] = {k: float(v) if isinstance(v, (np.integer, np.floating)) else v 
                                for k, v in stats.items()}
        json.dump(json_results, f, indent=2)
    
    print(f"\nğŸ’¾ åŸºå‡†æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    print("âš¡ Atom14 è½¬æ¢æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print(f"ğŸ”§ PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"ğŸ’» è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    print(f"ğŸ§® é“¾é—´é—´éš”: {CHAIN_GAP}")
    
    try:
        results = run_benchmark_suite()
        
        # è¾“å‡ºä¼˜åŒ–å»ºè®®
        print("\nğŸ¯ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        print("   1. å‡å°‘ Python å¾ªç¯ï¼Œä½¿ç”¨ PyTorch å¼ é‡æ“ä½œ")
        print("   2. ä¼˜åŒ–æ®‹åŸºåˆ†ç»„å’ŒåŸå­æ˜ å°„é€»è¾‘")
        print("   3. æ‰¹é‡å¤„ç†é“¾é—´é—´éš”è®¡ç®—")
        print("   4. å‡å°‘å­—å…¸æŸ¥æ‰¾å’Œåˆ—è¡¨æ“ä½œ")
        
        print("\nâœ… åŸºå‡†æµ‹è¯•å®Œæˆï¼è¯·ä¿å­˜æ­¤ç»“æœä½œä¸ºä¼˜åŒ–å‰çš„åŸºçº¿ã€‚")
        return 0
        
    except Exception as e:
        print(f"ğŸ’¥ åŸºå‡†æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main()) 