"""
Atom14 ç«¯åˆ°ç«¯é›†æˆæµ‹è¯• (å®Œæ•´ç‰ˆæœ¬)

æœ¬æ¨¡å—æä¾›å®Œæ•´çš„ Atom14 å·¥ä½œæµé›†æˆæµ‹è¯•ï¼Œè¦†ç›–ä»åŸå§‹ç»“æ„æ–‡ä»¶åˆ°æœ€ç»ˆè¾“å‡ºçš„
å®Œæ•´æ•°æ®æµï¼Œç¡®ä¿æ‰€æœ‰è½¬æ¢æ­¥éª¤çš„æ­£ç¡®æ€§å’Œæ•°æ®ä¸€è‡´æ€§ã€‚

é‡ç‚¹æµ‹è¯•ï¼š
1. è°ƒç”¨ batch_pdb_to_atom14.py è„šæœ¬è¿›è¡Œæ‰¹é‡è½¬æ¢
2. éªŒè¯ Atom14 å®ä¾‹å’Œå­—å…¸æ ¼å¼çš„ä¿å­˜/åŠ è½½
3. å°†ç»“æœè½¬æ¢ä¸º CIF æ–‡ä»¶è¿›è¡Œå¯è§†åŒ–éªŒè¯
4. çº¯ PyTorch åç«¯ï¼Œä¸ä½¿ç”¨ NumPy
5. ä¿å­˜æ‰€æœ‰ä¸­é—´ç»“æœä¾›æ‰‹åŠ¨éªŒè¯

æµ‹è¯•æµç¨‹ï¼š
1. CIF/PDB â†’ æ‰¹é‡è„šæœ¬ â†’ .pt æ–‡ä»¶
2. .pt æ–‡ä»¶ â†’ Atom14 å®ä¾‹/å­—å…¸ â†’ éªŒè¯ä¸€è‡´æ€§
3. Atom14 â†’ CIF é‡å»º â†’ å¯è§†åŒ–éªŒè¯
4. å®Œæ•´å·¥ä½œæµéªŒè¯å’Œæ€§èƒ½ç»Ÿè®¡
"""

import sys
import subprocess
import time
import json
import shutil
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional

import pytest
import torch

# æ·»åŠ æºç è·¯å¾„
sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent / "src"))

from protein_tensor import load_structure
from protrepr.core.atom14 import Atom14


class TestAtom14EndToEnd:
    """Atom14 ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•ç±»"""
    
    @pytest.fixture(scope="class")
    def test_output_dir(self) -> Path:
        """åˆ›å»ºæµ‹è¯•è¾“å‡ºç›®å½•"""
        output_dir = Path(__file__).parent / "test_results"
        output_dir.mkdir(exist_ok=True)
        return output_dir
    
    @pytest.fixture(scope="class") 
    def test_data_files(self) -> List[Path]:
        """è·å–æµ‹è¯•ç”¨çš„ CIF æ–‡ä»¶"""
        data_dir = Path(__file__).parent.parent / "data"
        test_files = []
        
        # æŸ¥æ‰¾å¯ç”¨çš„æµ‹è¯•æ–‡ä»¶
        for pattern in ["*.cif", "*.pdb"]:
            test_files.extend(data_dir.glob(pattern))
        
        if not test_files:
            pytest.skip("æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶")
        
        return test_files[:2]  # é™åˆ¶ä¸ºå‰ä¸¤ä¸ªæ–‡ä»¶ï¼Œé¿å…æµ‹è¯•æ—¶é—´è¿‡é•¿
    
    @pytest.fixture(scope="class")
    def script_path(self) -> Path:
        """è·å–æ‰¹é‡è½¬æ¢è„šæœ¬è·¯å¾„"""
        script_path = Path(__file__).parent.parent.parent / "scripts" / "batch_pdb_to_atom14.py"
        if not script_path.exists():
            pytest.skip(f"æ‰¹é‡è½¬æ¢è„šæœ¬ä¸å­˜åœ¨: {script_path}")
        return script_path

    def test_batch_script_single_file(self, test_data_files: List[Path], test_output_dir: Path, script_path: Path):
        """æµ‹è¯•æ‰¹é‡è„šæœ¬å¤„ç†å•ä¸ªæ–‡ä»¶"""
        test_file = test_data_files[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶
        output_subdir = test_output_dir / "batch_script_single"
        output_subdir.mkdir(exist_ok=True)
        
        print(f"\nğŸ§ª æµ‹è¯•æ‰¹é‡è„šæœ¬å¤„ç†å•ä¸ªæ–‡ä»¶: {test_file.name}")
        
        # è°ƒç”¨æ‰¹é‡è½¬æ¢è„šæœ¬
        cmd = [
            sys.executable, str(script_path),
            str(test_file),
            str(output_subdir),
            "--device", "cpu",
            "--verbose"
        ]
        
        start_time = time.time()
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path.cwd())
        execution_time = time.time() - start_time
        
        # ä¿å­˜è„šæœ¬æ‰§è¡Œç»“æœ
        script_result = {
            "command": " ".join(cmd),
            "return_code": result.returncode,
            "execution_time": execution_time,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "input_file": str(test_file),
            "output_dir": str(output_subdir)
        }
        
        with open(output_subdir / "script_execution_result.json", 'w', encoding='utf-8') as f:
            json.dump(script_result, f, indent=2, ensure_ascii=False)
        
        # éªŒè¯è„šæœ¬æ‰§è¡ŒæˆåŠŸ
        assert result.returncode == 0, f"è„šæœ¬æ‰§è¡Œå¤±è´¥: {result.stderr}"
        
        # æŸ¥æ‰¾ç”Ÿæˆçš„ .pt æ–‡ä»¶
        pt_files = list(output_subdir.glob("*.pt"))
        assert len(pt_files) > 0, "æ²¡æœ‰ç”Ÿæˆ .pt æ–‡ä»¶"
        
        pt_file = pt_files[0]
        print(f"âœ… ç”Ÿæˆæ–‡ä»¶: {pt_file.name} ({pt_file.stat().st_size} bytes)")
        
        # éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶å¯ä»¥åŠ è½½
        self._verify_pt_file(pt_file, output_subdir)

    def test_batch_script_directory(self, test_data_files: List[Path], test_output_dir: Path, script_path: Path):
        """æµ‹è¯•æ‰¹é‡è„šæœ¬å¤„ç†ç›®å½•"""
        print(f"\nğŸ§ª æµ‹è¯•æ‰¹é‡è„šæœ¬å¤„ç†ç›®å½•")
        
        # åˆ›å»ºè¾“å…¥ç›®å½•å¹¶å¤åˆ¶æµ‹è¯•æ–‡ä»¶
        input_dir = test_output_dir / "batch_input"
        input_dir.mkdir(exist_ok=True)
        
        for test_file in test_data_files:
            shutil.copy2(test_file, input_dir / test_file.name)
        
        output_subdir = test_output_dir / "batch_script_directory"
        output_subdir.mkdir(exist_ok=True)
        
        # è°ƒç”¨æ‰¹é‡è½¬æ¢è„šæœ¬
        cmd = [
            sys.executable, str(script_path),
            str(input_dir),
            str(output_subdir),
            "--device", "cpu",
            "--workers", "2",
            "--save-stats", str(output_subdir / "batch_stats.json"),
            "--verbose"
        ]
        
        start_time = time.time()
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path.cwd())
        execution_time = time.time() - start_time
        
        # ä¿å­˜æ‰¹é‡å¤„ç†ç»“æœ
        batch_result = {
            "command": " ".join(cmd),
            "return_code": result.returncode,
            "execution_time": execution_time,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "input_files": [f.name for f in test_data_files],
            "input_dir": str(input_dir),
            "output_dir": str(output_subdir)
        }
        
        with open(output_subdir / "batch_execution_result.json", 'w', encoding='utf-8') as f:
            json.dump(batch_result, f, indent=2, ensure_ascii=False)
        
        # éªŒè¯è„šæœ¬æ‰§è¡ŒæˆåŠŸ
        assert result.returncode == 0, f"æ‰¹é‡è„šæœ¬æ‰§è¡Œå¤±è´¥: {result.stderr}"
        
        # æŸ¥æ‰¾ç”Ÿæˆçš„ .pt æ–‡ä»¶
        pt_files = list(output_subdir.glob("*.pt"))
        assert len(pt_files) >= 1, "æ²¡æœ‰ç”Ÿæˆè¶³å¤Ÿçš„ .pt æ–‡ä»¶"
        
        print(f"âœ… æ‰¹é‡å¤„ç†ç”Ÿæˆ {len(pt_files)} ä¸ªæ–‡ä»¶")
        
        # éªŒè¯æ¯ä¸ªç”Ÿæˆçš„æ–‡ä»¶
        for pt_file in pt_files:
            self._verify_pt_file(pt_file, output_subdir)
        
        # æ¸…ç†è¾“å…¥ç›®å½•
        shutil.rmtree(input_dir, ignore_errors=True)

    def test_atom14_save_load_formats(self, test_data_files: List[Path], test_output_dir: Path):
        """æµ‹è¯• Atom14 çš„ä¿å­˜å’ŒåŠ è½½æ ¼å¼"""
        test_file = test_data_files[0]
        format_test_dir = test_output_dir / "format_tests"
        format_test_dir.mkdir(exist_ok=True)
        
        print(f"\nğŸ§ª æµ‹è¯• Atom14 ä¿å­˜/åŠ è½½æ ¼å¼")
        
        # åŠ è½½åŸå§‹ç»“æ„
        protein = load_structure(test_file)
        atom14_original = Atom14.from_protein_tensor(protein)
        
        print(f"ğŸ“Š åŸå§‹æ•°æ®: {atom14_original.num_residues} æ®‹åŸº, {atom14_original.num_chains} é“¾")
        
        # æµ‹è¯•ç»“æœè®°å½•
        format_results = {
            "original_info": {
                "num_residues": atom14_original.num_residues,
                "num_chains": atom14_original.num_chains,
                "coords_shape": list(atom14_original.coords.shape),
                "device": str(atom14_original.device)
            },
            "tests": {}
        }
        
        # 1. æµ‹è¯•å®ä¾‹æ ¼å¼ä¿å­˜å’ŒåŠ è½½
        instance_file = format_test_dir / "atom14_instance.pt"
        start_time = time.time()
        atom14_original.save(str(instance_file), save_as_instance=True)
        save_time = time.time() - start_time
        
        start_time = time.time()
        atom14_instance = Atom14.load(str(instance_file))
        load_time = time.time() - start_time
        
        # éªŒè¯å®ä¾‹ä¸€è‡´æ€§
        instance_consistent = self._check_consistency(atom14_original, atom14_instance)
        
        format_results["tests"]["instance_format"] = {
            "file_size": instance_file.stat().st_size,
            "save_time": save_time,
            "load_time": load_time,
            "data_consistent": instance_consistent,
            "file_path": str(instance_file)
        }
        
        print(f"âœ… å®ä¾‹æ ¼å¼: ä¿å­˜ {save_time:.3f}s, åŠ è½½ {load_time:.3f}s, å¤§å° {instance_file.stat().st_size} bytes")
        
        # 2. æµ‹è¯•å­—å…¸æ ¼å¼ä¿å­˜å’ŒåŠ è½½
        dict_file = format_test_dir / "atom14_dict.pt"
        start_time = time.time()
        atom14_original.save(str(dict_file), save_as_instance=False)
        save_time = time.time() - start_time
        
        start_time = time.time()
        atom14_dict = Atom14.load(str(dict_file))
        load_time = time.time() - start_time
        
        # éªŒè¯å­—å…¸ä¸€è‡´æ€§
        dict_consistent = self._check_consistency(atom14_original, atom14_dict)
        
        format_results["tests"]["dict_format"] = {
            "file_size": dict_file.stat().st_size,
            "save_time": save_time,
            "load_time": load_time,
            "data_consistent": dict_consistent,
            "file_path": str(dict_file)
        }
        
        print(f"âœ… å­—å…¸æ ¼å¼: ä¿å­˜ {save_time:.3f}s, åŠ è½½ {load_time:.3f}s, å¤§å° {dict_file.stat().st_size} bytes")
        
        # 3. æµ‹è¯•äº¤å‰ä¸€è‡´æ€§ï¼ˆå®ä¾‹ vs å­—å…¸ï¼‰
        cross_consistent = self._check_consistency(atom14_instance, atom14_dict)
        format_results["cross_consistency"] = cross_consistent
        
        # ä¿å­˜æ ¼å¼æµ‹è¯•ç»“æœ
        with open(format_test_dir / "format_test_results.json", 'w', encoding='utf-8') as f:
            json.dump(format_results, f, indent=2, ensure_ascii=False, default=str)
        
        # æ–­è¨€éªŒè¯
        assert instance_consistent, "å®ä¾‹æ ¼å¼æ•°æ®ä¸ä¸€è‡´"
        assert dict_consistent, "å­—å…¸æ ¼å¼æ•°æ®ä¸ä¸€è‡´"
        assert cross_consistent, "å®ä¾‹å’Œå­—å…¸æ ¼å¼äº¤å‰éªŒè¯ä¸ä¸€è‡´"

    def test_cif_reconstruction(self, test_data_files: List[Path], test_output_dir: Path):
        """æµ‹è¯• CIF æ–‡ä»¶é‡å»ºå’Œå¯è§†åŒ–éªŒè¯"""
        test_file = test_data_files[0]
        cif_test_dir = test_output_dir / "cif_reconstruction"
        cif_test_dir.mkdir(exist_ok=True)
        
        print(f"\nğŸ§ª æµ‹è¯• CIF æ–‡ä»¶é‡å»º")
        
        # åŠ è½½åŸå§‹ç»“æ„
        protein = load_structure(test_file)
        atom14 = Atom14.from_protein_tensor(protein)
        
        # é‡å»ºç»“æœè®°å½•
        reconstruction_results = {
            "original_file": str(test_file),
            "original_size": test_file.stat().st_size,
            "reconstructions": {}
        }
        
        # 1. ä»å®ä¾‹æ ¼å¼é‡å»º CIF
        instance_file = cif_test_dir / "atom14_instance.pt"
        atom14.save(str(instance_file), save_as_instance=True)
        atom14_loaded = Atom14.load(str(instance_file))
        
        cif_from_instance = cif_test_dir / "reconstructed_from_instance.cif"
        start_time = time.time()
        atom14_loaded.to_cif(str(cif_from_instance))
        reconstruction_time = time.time() - start_time
        
        reconstruction_results["reconstructions"]["from_instance"] = {
            "reconstruction_time": reconstruction_time,
            "file_size": cif_from_instance.stat().st_size,
            "file_path": str(cif_from_instance)
        }
        
        print(f"âœ… ä»å®ä¾‹é‡å»º: {reconstruction_time:.3f}s, å¤§å° {cif_from_instance.stat().st_size} bytes")
        
        # 2. ä»å­—å…¸æ ¼å¼é‡å»º CIF
        dict_file = cif_test_dir / "atom14_dict.pt"
        atom14.save(str(dict_file), save_as_instance=False)
        atom14_dict = Atom14.load(str(dict_file))
        
        cif_from_dict = cif_test_dir / "reconstructed_from_dict.cif"
        start_time = time.time()
        atom14_dict.to_cif(str(cif_from_dict))
        reconstruction_time = time.time() - start_time
        
        reconstruction_results["reconstructions"]["from_dict"] = {
            "reconstruction_time": reconstruction_time,
            "file_size": cif_from_dict.stat().st_size,
            "file_path": str(cif_from_dict)
        }
        
        print(f"âœ… ä»å­—å…¸é‡å»º: {reconstruction_time:.3f}s, å¤§å° {cif_from_dict.stat().st_size} bytes")
        
        # 3. ç›´æ¥é‡å»ºï¼ˆæ— ä¸­é—´ä¿å­˜ï¼‰
        cif_direct = cif_test_dir / "reconstructed_direct.cif"
        start_time = time.time()
        atom14.to_cif(str(cif_direct))
        reconstruction_time = time.time() - start_time
        
        reconstruction_results["reconstructions"]["direct"] = {
            "reconstruction_time": reconstruction_time,
            "file_size": cif_direct.stat().st_size,
            "file_path": str(cif_direct)
        }
        
        print(f"âœ… ç›´æ¥é‡å»º: {reconstruction_time:.3f}s, å¤§å° {cif_direct.stat().st_size} bytes")
        
        # ä¿å­˜é‡å»ºç»“æœ
        with open(cif_test_dir / "reconstruction_results.json", 'w', encoding='utf-8') as f:
            json.dump(reconstruction_results, f, indent=2, ensure_ascii=False, default=str)
        
        # éªŒè¯æ‰€æœ‰æ–‡ä»¶éƒ½æˆåŠŸç”Ÿæˆ
        assert cif_from_instance.exists(), "ä»å®ä¾‹é‡å»ºçš„ CIF æ–‡ä»¶æœªç”Ÿæˆ"
        assert cif_from_dict.exists(), "ä»å­—å…¸é‡å»ºçš„ CIF æ–‡ä»¶æœªç”Ÿæˆ"
        assert cif_direct.exists(), "ç›´æ¥é‡å»ºçš„ CIF æ–‡ä»¶æœªç”Ÿæˆ"
        
        print(f"ğŸ“ å¯è§†åŒ–éªŒè¯æ–‡ä»¶å·²ä¿å­˜åˆ°: {cif_test_dir}")

    def test_comprehensive_workflow(self, test_data_files: List[Path], test_output_dir: Path, script_path: Path):
        """æµ‹è¯•å®Œæ•´çš„ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹"""
        workflow_dir = test_output_dir / "comprehensive_workflow"
        workflow_dir.mkdir(exist_ok=True)
        
        print(f"\nğŸ§ª æµ‹è¯•å®Œæ•´ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹")
        
        workflow_results = {
            "start_time": time.time(),
            "steps": {},
            "files_generated": [],
            "performance_metrics": {}
        }
        
        # æ­¥éª¤ 1: ä½¿ç”¨æ‰¹é‡è„šæœ¬è½¬æ¢æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
        print("ğŸ“ æ­¥éª¤ 1: æ‰¹é‡è½¬æ¢")
        
        # åˆ›å»ºè¾“å…¥ç›®å½•
        input_dir = workflow_dir / "input_files"
        input_dir.mkdir(exist_ok=True)
        for test_file in test_data_files:
            shutil.copy2(test_file, input_dir / test_file.name)
        
        # æ‰¹é‡è½¬æ¢
        script_output_dir = workflow_dir / "script_output"
        script_output_dir.mkdir(exist_ok=True)
        
        cmd = [
            sys.executable, str(script_path),
            str(input_dir),
            str(script_output_dir),
            "--device", "cpu",
            "--workers", "2",
            "--save-stats", str(workflow_dir / "batch_statistics.json")
        ]
        
        step_start = time.time()
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path.cwd())
        step_time = time.time() - step_start
        
        workflow_results["steps"]["batch_conversion"] = {
            "success": result.returncode == 0,
            "execution_time": step_time,
            "files_processed": len(test_data_files),
            "command": " ".join(cmd)
        }
        
        assert result.returncode == 0, f"æ‰¹é‡è½¬æ¢å¤±è´¥: {result.stderr}"
        print(f"âœ… æ‰¹é‡è½¬æ¢å®Œæˆ: {step_time:.2f}s")
        
        # æ­¥éª¤ 2: éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
        print("ğŸ“ æ­¥éª¤ 2: æ–‡ä»¶éªŒè¯")
        pt_files = list(script_output_dir.glob("*.pt"))
        workflow_results["files_generated"] = [str(f) for f in pt_files]
        
        # æ­¥éª¤ 3: æµ‹è¯•æ¯ä¸ªç”Ÿæˆæ–‡ä»¶çš„è½¬æ¢èƒ½åŠ›
        print("ğŸ“ æ­¥éª¤ 3: æ ¼å¼è½¬æ¢æµ‹è¯•")
        conversion_results = {}
        
        for i, pt_file in enumerate(pt_files):
            file_stem = pt_file.stem
            print(f"  å¤„ç†æ–‡ä»¶ {i+1}/{len(pt_files)}: {file_stem}")
            
            # åŠ è½½ Atom14
            atom14 = Atom14.load(str(pt_file))
            
            # æµ‹è¯•å®ä¾‹ä¿å­˜
            instance_file = workflow_dir / f"{file_stem}_instance.pt"
            atom14.save(str(instance_file), save_as_instance=True)
            atom14_instance = Atom14.load(str(instance_file))
            
            # æµ‹è¯•å­—å…¸ä¿å­˜
            dict_file = workflow_dir / f"{file_stem}_dict.pt"
            atom14.save(str(dict_file), save_as_instance=False)
            atom14_dict = Atom14.load(str(dict_file))
            
            # æ•°æ®ä¸€è‡´æ€§éªŒè¯
            instance_consistent = self._check_consistency(atom14, atom14_instance)
            dict_consistent = self._check_consistency(atom14, atom14_dict)
            
            # CIF é‡å»º
            cif_output_dir = workflow_dir / "cif_outputs"
            cif_output_dir.mkdir(exist_ok=True)
            
            cif_file = cif_output_dir / f"{file_stem}_reconstructed.cif"
            atom14.to_cif(str(cif_file))
            
            conversion_results[file_stem] = {
                "num_residues": atom14.num_residues,
                "num_chains": atom14.num_chains,
                "instance_consistent": instance_consistent,
                "dict_consistent": dict_consistent,
                "cif_generated": cif_file.exists(),
                "cif_size": cif_file.stat().st_size if cif_file.exists() else 0
            }
        
        workflow_results["conversion_results"] = conversion_results
        workflow_results["end_time"] = time.time()
        workflow_results["total_duration"] = workflow_results["end_time"] - workflow_results["start_time"]
        
        # ä¿å­˜å®Œæ•´å·¥ä½œæµç»“æœ
        with open(workflow_dir / "comprehensive_workflow_results.json", 'w', encoding='utf-8') as f:
            json.dump(workflow_results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… å®Œæ•´å·¥ä½œæµç¨‹å®Œæˆ: {workflow_results['total_duration']:.2f}s")
        print(f"ğŸ“Š å¤„ç†äº† {len(pt_files)} ä¸ªæ–‡ä»¶")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åˆ°: {workflow_dir}")
        
        # éªŒè¯æ‰€æœ‰æ­¥éª¤æˆåŠŸ
        assert workflow_results["steps"]["batch_conversion"]["success"], "æ‰¹é‡è½¬æ¢æ­¥éª¤å¤±è´¥"
        assert len(pt_files) > 0, "æ²¡æœ‰ç”Ÿæˆ PT æ–‡ä»¶"
        assert all(r["cif_generated"] for r in conversion_results.values()), "éƒ¨åˆ† CIF æ–‡ä»¶æœªç”Ÿæˆ"

    def _verify_pt_file(self, pt_file: Path, output_dir: Path) -> Dict[str, Any]:
        """éªŒè¯å•ä¸ª .pt æ–‡ä»¶çš„å®Œæ•´æ€§"""
        verification_result = {
            "file_path": str(pt_file),
            "file_size": pt_file.stat().st_size,
            "load_success": False,
            "atom14_info": {},
            "consistency_test": False,
            "cif_generation": False
        }
        
        try:
            # åŠ è½½æ•°æ®
            atom14 = Atom14.load(str(pt_file))
            verification_result["load_success"] = True
            
            # è®°å½•åŸºæœ¬ä¿¡æ¯
            verification_result["atom14_info"] = {
                "num_residues": atom14.num_residues,
                "num_chains": atom14.num_chains,
                "coords_shape": list(atom14.coords.shape),
                "device": str(atom14.device)
            }
            
            # éªŒè¯åŸºæœ¬å±æ€§
            assert atom14.coords.shape[-2:] == (14, 3), f"åæ ‡å½¢çŠ¶é”™è¯¯: {atom14.coords.shape}"
            assert atom14.atom_mask.shape[-1] == 14, f"åŸå­æ©ç å½¢çŠ¶é”™è¯¯: {atom14.atom_mask.shape}"
            assert atom14.num_residues > 0, "æ®‹åŸºæ•°é‡ä¸ºé›¶"
            
            # æµ‹è¯•ä¿å­˜å’Œé‡æ–°åŠ è½½
            test_file = output_dir / f"{pt_file.stem}_verification.pt"
            atom14.save(str(test_file), save_as_instance=True)
            atom14_reloaded = Atom14.load(str(test_file))
            
            # éªŒè¯ä¸€è‡´æ€§
            verification_result["consistency_test"] = self._check_consistency(atom14, atom14_reloaded)
            
            # ç”Ÿæˆ CIF æ–‡ä»¶
            cif_file = output_dir / f"{pt_file.stem}_verification.cif"
            atom14.to_cif(str(cif_file))
            verification_result["cif_generation"] = cif_file.exists()
            
            if cif_file.exists():
                verification_result["cif_size"] = cif_file.stat().st_size
                
        except Exception as e:
            verification_result["error"] = str(e)
        
        # ä¿å­˜éªŒè¯ç»“æœ
        result_file = output_dir / f"{pt_file.stem}_verification_result.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(verification_result, f, indent=2, ensure_ascii=False, default=str)
        
        return verification_result
    
    def _check_consistency(self, atom14_1: Atom14, atom14_2: Atom14) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ª Atom14 å®ä¾‹çš„æ•°æ®ä¸€è‡´æ€§"""
        try:
            # éªŒè¯åæ ‡
            coords_match = torch.allclose(atom14_1.coords, atom14_2.coords, rtol=1e-5, atol=1e-6)
            if not coords_match:
                return False
            
            # éªŒè¯æ©ç 
            if not torch.equal(atom14_1.atom_mask, atom14_2.atom_mask):
                return False
            
            if not torch.equal(atom14_1.res_mask, atom14_2.res_mask):
                return False
            
            # éªŒè¯å…ƒæ•°æ®
            if not torch.equal(atom14_1.chain_ids, atom14_2.chain_ids):
                return False
            
            if not torch.equal(atom14_1.residue_types, atom14_2.residue_types):
                return False
            
            return True
            
        except Exception:
            return False


# ç‹¬ç«‹æµ‹è¯•å‡½æ•°ï¼ˆå¯ä»¥ç›´æ¥è¿è¡Œï¼‰
def test_quick_verification():
    """å¿«é€ŸéªŒè¯æµ‹è¯•å‡½æ•°"""
    print("\nğŸš€ Atom14 å¿«é€ŸåŠŸèƒ½éªŒè¯")
    
    # è·å–æµ‹è¯•æ•°æ®
    data_dir = Path(__file__).parent.parent / "data"
    test_files = list(data_dir.glob("*.cif"))[:1]
    
    if not test_files:
        pytest.skip("æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent / "test_results" / "quick_verification"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # éªŒè¯ Atom14 åŸºæœ¬åŠŸèƒ½
    protein = load_structure(test_files[0])
    atom14 = Atom14.from_protein_tensor(protein)
    
    # æµ‹è¯•ä¿å­˜å’ŒåŠ è½½
    test_file = output_dir / "quick_test.pt"
    atom14.save(str(test_file), save_as_instance=True)
    atom14_loaded = Atom14.load(str(test_file))
    
    # ç”Ÿæˆ CIF ç”¨äºéªŒè¯
    cif_file = output_dir / "quick_verification.cif"
    atom14_loaded.to_cif(str(cif_file))
    
    print(f"âœ… å¿«é€ŸéªŒè¯å®Œæˆ")
    print(f"ğŸ“ éªŒè¯æ–‡ä»¶ä¿å­˜åˆ°: {output_dir}")
    print(f"ğŸ”¬ å¯è§†åŒ–éªŒè¯æ–‡ä»¶: {cif_file}")


if __name__ == "__main__":
    # å…è®¸ç›´æ¥è¿è¡Œæµ‹è¯•
    print("ğŸ§ª è¿è¡Œ Atom14 ç«¯åˆ°ç«¯æµ‹è¯•")
    pytest.main([__file__, "-v", "-s", "--no-cov"])
